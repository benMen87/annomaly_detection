{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIPRO TIME SERIERS - ANOMALY DETECTION AND SEQUENCE PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build recurrent anttention based model**\n",
    "\n",
    "The idea being learn the sequential dependencys and structure via gated rnn,\n",
    "and to learn spatial structure and similarity via attention mechanism. \n",
    "\n",
    "The Attention used in this case is inspired by https://arxiv.org/pdf/1508.04025.pdf\n",
    "Where the context vector is appended to final hiddent state and are passed to output layer.\n",
    "This differs to the standerd case where context is appended to input of the reccurent cell.\n",
    "\n",
    "The RNN sequence is inspired by https://arxiv.org/pdf/1308.0850.pdf\n",
    "Where LSTM based models are used for pedicting next time step.\n",
    "\n",
    "The code is mostly based on code found here:\n",
    "http://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Recurrent model for capturing sequential information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SequencePredRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(SequencePredRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=False)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        output = inputs\n",
    "        for i in range(self.n_layers):\n",
    "            print('outshape {} hiddenshape {}'.format(inputs.size(), hidden.size()))\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Attention model utilize reccurnt ouputs and their spatial similarity for predicting next time step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttendAndPredict(nn.Module):\n",
    "    \"\"\"Attention nn module that is responsible for computing the alignment scores.\"\"\"\n",
    "\n",
    "    def __init__(self, method, hidden_size, output_size):\n",
    "        super(AttendAndPredict, self).__init__()\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Define layers\n",
    "        if self.method == 'general':\n",
    "            self.attention = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attention = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "            self.other = nn.Parameter(torch.FloatTensor(1, self.hidden_size))\n",
    "            \n",
    "        self.fc_out = nn.Linear(self.hidden_size * 2, self.output_size)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, hidden, M):\n",
    "        \"\"\"Attend over N rnn sequence prediction outputs till time t-1 (t-2-N...t-1).\n",
    "        \n",
    "        After creating variables to store the attention energies, calculate their \n",
    "        values for each encoder output and return the normalized values.\n",
    "        \n",
    "        Args:\n",
    "            M(seq_len,batch,input size): memory of which to attend over.\n",
    "            hidden(1, batch, input size): hidden state.\n",
    "            \n",
    "        Returns:\n",
    "             Normalized (0..1) energy values, re-sized to 1 x 1 x seq_len\n",
    "        \"\"\"\n",
    "        \n",
    "        seq_len = M.size()[0]\n",
    "        batch_size = M.size()[1]\n",
    "        \n",
    "        print(hidden.size())\n",
    "        # convert to batch first\n",
    "        M = M.permute(1,0,2)\n",
    "        hidden = hidden.permute(1,0,2)\n",
    "\n",
    "        energies = self._score(hidden, M)\n",
    "        a = F.softmax(energies)\n",
    "        print('a size {} M size {}'.format(a.size(), M.size()))\n",
    "        c = a.permute(0,2,1).bmm(M) #bmm(a.permute(0,2,1))\n",
    "        print('c size {} hidden size {}'.format(c.size(), hidden.size()))\n",
    "        next_timestep_prediction = self.fc_out(torch.cat((c.squeeze(1), hidden.squeeze(1)), 1))\n",
    "        \n",
    "        return next_timestep_prediction, a\n",
    "        \n",
    "    def _score(self, hidden, M):\n",
    "        \"\"\"\n",
    "        Calculate the relevance of a particular encoder output in respect to the decoder hidden.\n",
    "        Args:\n",
    "            hidden: decoder hidden output used for condition.\n",
    "            M(batch,seq_len,input_size): memory of which to attend over.\n",
    "            hidden(1, batch, input size): hidden state.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.method == 'dot':\n",
    "            # TODO: Not tested\n",
    "            energy = hidden.dot(M)\n",
    "        elif self.method == 'general':\n",
    "            energy = self.attention(M)\n",
    "            energy = torch.bmm(energy, hidden)#hidden.dot(energy)\n",
    "        elif self.method == 'concat':\n",
    "            # TODO: Not tested\n",
    "            energy = self.attention(torch.cat((hidden, M), 1))\n",
    "            energy = self.other.dor(energy)\n",
    "        return energy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqRnnAttnAndPred(nn.Module):\n",
    "    \"\"\"\n",
    "    SequenceAttnPred - Recurrent Atteniton based model for predicting next time step.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size,\n",
    "                 rnn_layers=1, atnn_method='general', memory_size=-1):\n",
    "        \"\"\"\n",
    "        args:\n",
    "        input_size: size of elemnt of sequnece.\n",
    "        hidden_size: size of hidden state of RNN (same as output if only 1 RNN).\n",
    "        output_size: size of output tensor.\n",
    "        rnn_layers: amount of stacked RNN's (see any basic seq2seq paper).\n",
    "        atnn_method: type of attention to use.\n",
    "        memory_size: amount of rnn output's to aggregate and attend over.\n",
    "        \"\"\"\n",
    "        super(SeqRnnAttnAndPred, self).__init__()\n",
    "        self._rnn_layer = SequencePredRNN(input_size, hidden_size, rnn_layers)\n",
    "        self._atnn_layer = AttendAndPredict(atnn_method, hidden_size, output_size)\n",
    "        self._memory_size = memory_size\n",
    "        self._batch_size = batch_size\n",
    "        self._hidden = Variable(torch.zeros(1, batch_size, hidden_size))\n",
    "        self._hidden = self._hidden.cuda() if USE_CUDA else self._hidden\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        args:\n",
    "        inputs(seq_len,batch,input_len): input sequence predict seq_len + 1\n",
    "        \"\"\"\n",
    "        seq_len = inputs.size()[0]\n",
    "        \n",
    "        # in case of 1 rnn layer output == hidden.\n",
    "        seqrnn_output, self._hidden = self._rnn_layer(inputs, self._hidden)\n",
    "        self.memory = seqrnn_output[-self._memory_size-1:-1]\n",
    "        self._hidden = seqrnn_output[-1].unsqueeze(0)\n",
    "        outputs, alignment = self._atnn_layer(self._hidden, self.memory)\n",
    "        return outputs, alignment\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training procedure**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train per time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_seq, model, criterion, optimizer):\n",
    "    \"\"\"\n",
    "    Train for a given sequence batch size.\n",
    "    Args:\n",
    "    input_seq(batch_size,seq_len,input_size): tensor containin sequences.\n",
    "    model: input model - batch is first dim.\n",
    "    criterion: distance measure i.e. l1, l2 etc.\n",
    "    optimizer: GD, ADAM etc.\n",
    "    \"\"\"  \n",
    "    preds, alignment = model(input_seq[:-1])\n",
    "    loss = criterion(preds, input_seq[-1])\n",
    "    print(loss)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.data[0]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a helper function to print time elapsed and estimated time remaining given the current time and progress %."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full train procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainIters(train_data, model, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    \n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss().cuda()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        \n",
    "        input_variable = train_data[iter,:].unsqueeze(-1).unsqueeze(-1)\n",
    "        double_batch_input = torch.cat((input_variable,input_variable),1)\n",
    "        \n",
    "        loss = train(double_batch_input, model, criterion, optimizer)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temprorery gen syntetic data for debugging model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "T = 20\n",
    "L = 1000\n",
    "N = 100\n",
    "\n",
    "x = np.empty((N, L), 'float32')\n",
    "x[:] = np.array(range(L)) + np.random.randint(-4 * T, 4 * T, N).reshape(N, 1)\n",
    "data = Variable(torch.from_numpy(np.sin(x / 1.0 / T).astype('float32')), requires_grad=False)\n",
    "data = data.cuda() if USE_CUDA else data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example data shape: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f14fc88bb10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMfYhYvKPESNGjH2I/x/OFmHRmfxP/gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f14f4d15550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('example data shape: '.format(data.size()))\n",
    "show_plot(data[1,:].data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Main Entry Point **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outshape torch.Size([999, 2, 1]) hiddenshape torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "a size torch.Size([2, 10, 1]) M size torch.Size([2, 10, 1])\n",
      "c size torch.Size([2, 1, 1]) hidden size torch.Size([2, 1, 1])\n",
      "Variable containing:\n",
      "1.00000e-02 *\n",
      "  4.3501\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "outshape torch.Size([999, 2, 1]) hiddenshape torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "a size torch.Size([2, 10, 1]) M size torch.Size([2, 10, 1])\n",
      "c size torch.Size([2, 1, 1]) hidden size torch.Size([2, 1, 1])\n",
      "Variable containing:\n",
      " 0.2829\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7b9c4728e2bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mseq_attn_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_attn_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_attn_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-3fbe0e7de47f>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(train_data, model, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdouble_batch_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_variable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_variable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdouble_batch_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b8c537942ab1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_seq, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/function.pyc\u001b[0m in \u001b[0;36m_do_backward\u001b[0;34m(self, gradients, retain_variables)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNestedIOFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/function.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, *gradients)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mnested_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_gradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iter_None_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mbackward_extended\u001b[0;34m(self, grad_output, grad_hy)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_hy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/function.pyc\u001b[0m in \u001b[0;36msaved_tensors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msaved_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0mflat_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNestedIOFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_save_nested\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "hidden_size = 1\n",
    "seq_attn_pred = SeqRnnAttnAndPred(input_size=1, hidden_size=1, output_size=1, batch_size=2,\n",
    "                  rnn_layers=1, atnn_method='general', memory_size=10)\n",
    "\n",
    "if USE_CUDA:\n",
    "    seq_attn_pred = seq_attn_pred.cuda()\n",
    "\n",
    "trainIters(data, seq_attn_pred, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
