{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIPRO TIME SERIERS - ANOMALY DETECTION AND SEQUENCE PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load NASA data \n",
    "\n",
    "[from dataset readme]\n",
    "The data are provided as a zip-compressed text file with 26 columns of numbers, separated by spaces. Each row is a snapshot of data taken during a single operational cycle, each column is a different variable. The columns correspond to:\n",
    "\n",
    "1)  unit number  \n",
    "2)  time, in cycles  \n",
    "3)  operational setting 1  \n",
    "4)  operational setting 2  \n",
    "5)  operational setting 3  \n",
    "6)  sensor measurement  1  \n",
    "7)  sensor measurement  2  \n",
    "...  \n",
    "26) sensor measurement  26  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './nasa_data/train_FD001.txt'\n",
    "header_names = ['unit number', 'time in cycles']  + ['operational setting %d'%i for i in range(1, 4)] + [ 'sensor measurement %d'%i for i in range(1, 24)]\n",
    "df_train = pd.read_csv(file_path, sep=' ', header=None, names=header_names)\n",
    "df_train = df_train.dropna(axis=1, how='all')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './nasa_data/test_FD001.txt'\n",
    "header_names = ['unit number', 'time in cycles']  + ['operational setting %d'%i for i in range(1, 4)] + [ 'sensor measurement %d'%i for i in range(1, 24)]\n",
    "df_test = pd.read_csv(file_path, sep=' ', header=None, names=header_names)\n",
    "df_test = df_test.dropna(axis=1, how='all')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit = np.random.randint(1, df_test['unit number'].max())\n",
    "window_sz = 50\n",
    "\n",
    "plot_example = df_test[(df_test['unit number'] == unit) &  (df_test['time in cycles'] < window_sz) ]\n",
    "print('First 50 cycles')\n",
    "ax = plot_example.plot(subplots=True, sharex=True, figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_of_cycles = df_test[(df_test['unit number'] == unit)]['time in cycles'].max()\n",
    "plot_example = df_test[(df_test['unit number'] == unit) &  (amount_of_cycles - window_sz < df_test['time in cycles']) ]\n",
    "print('Last 50 cycles')\n",
    "ax = plot_example.plot(subplots=True, sharex=True, figsize=(20,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess and normolize data\n",
    "we use minmax norm:**  \n",
    "`X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "X_scaled = X_std * (max - min) + min`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit number</th>\n",
       "      <th>time in cycles</th>\n",
       "      <th>operational setting 1</th>\n",
       "      <th>operational setting 2</th>\n",
       "      <th>operational setting 3</th>\n",
       "      <th>sensor measurement 1</th>\n",
       "      <th>sensor measurement 2</th>\n",
       "      <th>sensor measurement 3</th>\n",
       "      <th>sensor measurement 4</th>\n",
       "      <th>sensor measurement 5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor measurement 12</th>\n",
       "      <th>sensor measurement 13</th>\n",
       "      <th>sensor measurement 14</th>\n",
       "      <th>sensor measurement 15</th>\n",
       "      <th>sensor measurement 16</th>\n",
       "      <th>sensor measurement 17</th>\n",
       "      <th>sensor measurement 18</th>\n",
       "      <th>sensor measurement 19</th>\n",
       "      <th>sensor measurement 20</th>\n",
       "      <th>sensor measurement 21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183735</td>\n",
       "      <td>0.406802</td>\n",
       "      <td>0.309757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633262</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.199608</td>\n",
       "      <td>0.363986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.724662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.453019</td>\n",
       "      <td>0.352633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765458</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.162813</td>\n",
       "      <td>0.411312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.731014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.369523</td>\n",
       "      <td>0.370527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795309</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.171793</td>\n",
       "      <td>0.357445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.621375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.256159</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889126</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.174889</td>\n",
       "      <td>0.166603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.662386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.390805</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.257467</td>\n",
       "      <td>0.404625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.174734</td>\n",
       "      <td>0.402078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.704502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit number  time in cycles  operational setting 1  operational setting 2  \\\n",
       "0            1               1               0.459770               0.166667   \n",
       "1            1               2               0.609195               0.250000   \n",
       "2            1               3               0.252874               0.750000   \n",
       "3            1               4               0.540230               0.500000   \n",
       "4            1               5               0.390805               0.333333   \n",
       "\n",
       "   operational setting 3  sensor measurement 1  sensor measurement 2  \\\n",
       "0                    0.0                   0.0              0.183735   \n",
       "1                    0.0                   0.0              0.283133   \n",
       "2                    0.0                   0.0              0.343373   \n",
       "3                    0.0                   0.0              0.343373   \n",
       "4                    0.0                   0.0              0.349398   \n",
       "\n",
       "   sensor measurement 3  sensor measurement 4  sensor measurement 5  \\\n",
       "0              0.406802              0.309757                   0.0   \n",
       "1              0.453019              0.352633                   0.0   \n",
       "2              0.369523              0.370527                   0.0   \n",
       "3              0.256159              0.331195                   0.0   \n",
       "4              0.257467              0.404625                   0.0   \n",
       "\n",
       "           ...            sensor measurement 12  sensor measurement 13  \\\n",
       "0          ...                         0.633262               0.205882   \n",
       "1          ...                         0.765458               0.279412   \n",
       "2          ...                         0.795309               0.220588   \n",
       "3          ...                         0.889126               0.294118   \n",
       "4          ...                         0.746269               0.235294   \n",
       "\n",
       "   sensor measurement 14  sensor measurement 15  sensor measurement 16  \\\n",
       "0               0.199608               0.363986                    0.0   \n",
       "1               0.162813               0.411312                    0.0   \n",
       "2               0.171793               0.357445                    0.0   \n",
       "3               0.174889               0.166603                    0.0   \n",
       "4               0.174734               0.402078                    0.0   \n",
       "\n",
       "   sensor measurement 17  sensor measurement 18  sensor measurement 19  \\\n",
       "0               0.333333                    0.0                    0.0   \n",
       "1               0.333333                    0.0                    0.0   \n",
       "2               0.166667                    0.0                    0.0   \n",
       "3               0.333333                    0.0                    0.0   \n",
       "4               0.416667                    0.0                    0.0   \n",
       "\n",
       "   sensor measurement 20  sensor measurement 21  \n",
       "0               0.713178               0.724662  \n",
       "1               0.666667               0.731014  \n",
       "2               0.627907               0.621375  \n",
       "3               0.573643               0.662386  \n",
       "4               0.589147               0.704502  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_normalize = df_train.columns.difference(['unit number', 'time in cycles'])\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(df_train[cols_normalize]), \n",
    "                             columns=cols_normalize, \n",
    "                             index=df_train.index)\n",
    "join_df = df_train[df_train.columns.difference(cols_normalize)].join(norm_train_df)\n",
    "df_train = join_df.reindex(columns = df_train.columns)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit number</th>\n",
       "      <th>time in cycles</th>\n",
       "      <th>operational setting 1</th>\n",
       "      <th>operational setting 2</th>\n",
       "      <th>operational setting 3</th>\n",
       "      <th>sensor measurement 1</th>\n",
       "      <th>sensor measurement 2</th>\n",
       "      <th>sensor measurement 3</th>\n",
       "      <th>sensor measurement 4</th>\n",
       "      <th>sensor measurement 5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor measurement 12</th>\n",
       "      <th>sensor measurement 13</th>\n",
       "      <th>sensor measurement 14</th>\n",
       "      <th>sensor measurement 15</th>\n",
       "      <th>sensor measurement 16</th>\n",
       "      <th>sensor measurement 17</th>\n",
       "      <th>sensor measurement 18</th>\n",
       "      <th>sensor measurement 19</th>\n",
       "      <th>sensor measurement 20</th>\n",
       "      <th>sensor measurement 21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545181</td>\n",
       "      <td>0.310661</td>\n",
       "      <td>0.269413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646055</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.132160</td>\n",
       "      <td>0.308965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.661834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0.379551</td>\n",
       "      <td>0.222316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739872</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.204768</td>\n",
       "      <td>0.213159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682171</td>\n",
       "      <td>0.686827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376506</td>\n",
       "      <td>0.346632</td>\n",
       "      <td>0.322248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699360</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.155640</td>\n",
       "      <td>0.458638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.721348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370482</td>\n",
       "      <td>0.285154</td>\n",
       "      <td>0.408001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573561</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.170090</td>\n",
       "      <td>0.257022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.662110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.580460</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391566</td>\n",
       "      <td>0.352082</td>\n",
       "      <td>0.332039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737740</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.152751</td>\n",
       "      <td>0.300885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.716377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit number  time in cycles  operational setting 1  operational setting 2  \\\n",
       "0            1               1               0.632184               0.750000   \n",
       "1            1               2               0.344828               0.250000   \n",
       "2            1               3               0.517241               0.583333   \n",
       "3            1               4               0.741379               0.500000   \n",
       "4            1               5               0.580460               0.500000   \n",
       "\n",
       "   operational setting 3  sensor measurement 1  sensor measurement 2  \\\n",
       "0                    0.0                   0.0              0.545181   \n",
       "1                    0.0                   0.0              0.150602   \n",
       "2                    0.0                   0.0              0.376506   \n",
       "3                    0.0                   0.0              0.370482   \n",
       "4                    0.0                   0.0              0.391566   \n",
       "\n",
       "   sensor measurement 3  sensor measurement 4  sensor measurement 5  \\\n",
       "0              0.310661              0.269413                   0.0   \n",
       "1              0.379551              0.222316                   0.0   \n",
       "2              0.346632              0.322248                   0.0   \n",
       "3              0.285154              0.408001                   0.0   \n",
       "4              0.352082              0.332039                   0.0   \n",
       "\n",
       "           ...            sensor measurement 12  sensor measurement 13  \\\n",
       "0          ...                         0.646055               0.220588   \n",
       "1          ...                         0.739872               0.264706   \n",
       "2          ...                         0.699360               0.220588   \n",
       "3          ...                         0.573561               0.250000   \n",
       "4          ...                         0.737740               0.220588   \n",
       "\n",
       "   sensor measurement 14  sensor measurement 15  sensor measurement 16  \\\n",
       "0               0.132160               0.308965                    0.0   \n",
       "1               0.204768               0.213159                    0.0   \n",
       "2               0.155640               0.458638                    0.0   \n",
       "3               0.170090               0.257022                    0.0   \n",
       "4               0.152751               0.300885                    0.0   \n",
       "\n",
       "   sensor measurement 17  sensor measurement 18  sensor measurement 19  \\\n",
       "0               0.333333                    0.0                    0.0   \n",
       "1               0.416667                    0.0                    0.0   \n",
       "2               0.416667                    0.0                    0.0   \n",
       "3               0.250000                    0.0                    0.0   \n",
       "4               0.166667                    0.0                    0.0   \n",
       "\n",
       "   sensor measurement 20  sensor measurement 21  \n",
       "0               0.558140               0.661834  \n",
       "1               0.682171               0.686827  \n",
       "2               0.728682               0.721348  \n",
       "3               0.666667               0.662110  \n",
       "4               0.658915               0.716377  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_test_df = pd.DataFrame(min_max_scaler.transform(df_test[cols_normalize]), \n",
    "                            columns=cols_normalize, \n",
    "                            index=df_test.index)\n",
    "df_test_join = df_test[df_test.columns.difference(cols_normalize)].join(norm_test_df)\n",
    "df_test = df_test_join.reindex(columns = df_test.columns)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given unit data frame generate all shifted sequences of length seq length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reshape features into (samples, time steps, features) \n",
    "def gen_sequence(id_df, seq_length, seq_cols):\n",
    "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
    "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
    "    we can use shorter ones \"\"\"\n",
    "    data_array = id_df[seq_cols].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
    "        yield data_array[start:stop, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the feature columns \n",
    "sensor_cols = ['sensor measurement ' + str(i) for i in range(1,22)]\n",
    "sequence_cols = ['operational setting 1', 'operational setting 2', 'operational setting 3']\n",
    "sequence_cols.extend(sensor_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator for the sequences\n",
    "seq_gen = (list(gen_sequence(df_train[df_train['unit number']==id], seq_length, sequence_cols)) \n",
    "           for id in df_train['unit number'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15631, 50, 24)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate sequences and convert to numpy array\n",
    "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
    "seq_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split to train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ratio = 0.05\n",
    "seq_count = seq_array.shape[0]\n",
    "valid_stop_idx = int(seq_count * valid_ratio)\n",
    "\n",
    "np.random.shuffle(seq_array)\n",
    "train_data = seq_array[valid_stop_idx:]\n",
    "valid_data = seq_array[:valid_stop_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Recurrent attention based model\n",
    "\n",
    "The idea being learn the sequential dependencys and structure via gated rnn,\n",
    "and to learn spatial structure and similarity via attention mechanism. \n",
    "\n",
    "The Attention used in this case is inspired by https://arxiv.org/pdf/1508.04025.pdf\n",
    "Where the context vector is appended to final hiddent state and are passed to output layer.\n",
    "This differs to the standerd case where context is appended to input of the reccurent cell.\n",
    "\n",
    "The RNN sequence is inspired by https://arxiv.org/pdf/1308.0850.pdf\n",
    "Where LSTM based models are used for pedicting next time step.\n",
    "\n",
    "The code is mostly based on code found here:\n",
    "http://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model: sequence --> GRU --> attention --> FC --> out**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Attention model utilize reccurnt ouputs and their spatial similarity for predicting next time step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttendAndPredict(nn.Module):\n",
    "    \"\"\"Attention nn module that is responsible for computing the alignment scores.\"\"\"\n",
    "\n",
    "    def __init__(self, method, hidden_size, output_size):\n",
    "        super(AttendAndPredict, self).__init__()\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Define layers\n",
    "        if self.method == 'general':\n",
    "            self.attention = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attention = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "            self.other = nn.Parameter(torch.FloatTensor(1, self.hidden_size))\n",
    "            \n",
    "        self.fc_c = nn.Linear(self.hidden_size * 2, self.output_size)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, hidden, M):\n",
    "        \"\"\"Attend over N rnn sequence prediction outputs till time t-1 (t-2-N...t-1).\n",
    "        \n",
    "        After creating variables to store the attention energies, calculate their \n",
    "        values for each encoder output and return the normalized values.\n",
    "        \n",
    "        Args:\n",
    "            M(mem_size,batch,input size): memory of which to attend over.\n",
    "            hidden(1, batch, input size): hidden state.\n",
    "            \n",
    "        Returns:\n",
    "             Normalized (0..1) energy values, re-sized to 1 x 1 x seq_len\n",
    "        \"\"\"\n",
    "        \n",
    "        mem_size = M.size()[0]\n",
    "        batch_size = M.size()[1]\n",
    "        \n",
    "        # convert to batch first\n",
    "        M = M.permute(1,0,2)\n",
    "        hidden = hidden.permute(1,2,0)\n",
    "\n",
    "        energies = self._score(hidden, M)\n",
    "        a = F.softmax(energies, dim=1)\n",
    "        c = a.permute(0,2,1).bmm(M)\n",
    "        next_hidden_state =  F.tanh(self.fc_c(torch.cat((c.squeeze(1), hidden.squeeze(2)), 1)))\n",
    "        \n",
    "        return next_hidden_state, a\n",
    "        \n",
    "    def _score(self, hidden, M):\n",
    "        \"\"\"\n",
    "        Calculate the relevance of a particular encoder output in respect to the decoder hidden.\n",
    "        Args:\n",
    "            hidden: decoder hidden output used for condition.\n",
    "            M(batch,seq_len,input_size): memory of which to attend over.\n",
    "            hidden(1, batch, input size): hidden state.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.method == 'dot':\n",
    "            # TODO: Not tested\n",
    "            energy = hidden.dot(M)\n",
    "        elif self.method == 'general':\n",
    "            energy = self.attention(M)\n",
    "            energy = torch.bmm(energy, hidden)#hidden.dot(energy)\n",
    "        elif self.method == 'concat':\n",
    "            # TODO: Not tested\n",
    "            energy = self.attention(torch.cat((hidden, M), 1))\n",
    "            energy = self.other.dor(energy)\n",
    "        return energy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqRnnAttnAndPred(nn.Module):\n",
    "    \"\"\"\n",
    "    SequenceAttnPred - Recurrent Atteniton based model for predicting next time step.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size,\n",
    "                 rnn_layers=1, atnn_method='general', memory_size=-1):\n",
    "        \"\"\"\n",
    "        args:\n",
    "        input_size: size of elemnt of sequnece.\n",
    "        hidden_size: size of hidden state of RNN (same as output if only 1 RNN).\n",
    "        output_size: size of output tensor.\n",
    "        rnn_layers: amount of stacked RNN's (see any basic seq2seq paper).\n",
    "        atnn_method: type of attention to use.\n",
    "        memory_size: amount of rnn output's to aggregate and attend over.\n",
    "        \"\"\"\n",
    "        super(SeqRnnAttnAndPred, self).__init__()\n",
    "        self._rnn_layer = nn.GRU(input_size, hidden_size, num_layers=rnn_layers)\n",
    "        self._atnn_layer = AttendAndPredict(atnn_method, hidden_size, output_size)\n",
    "        self._memory_size = memory_size\n",
    "        self._rnn_layers = rnn_layers\n",
    "        self._hidden_size = hidden_size\n",
    "        self._output_size = output_size\n",
    "        self._fc_out = nn.Linear(self._hidden_size , self._output_size)\n",
    "\n",
    "        \n",
    "    def forward(self, inputs, hidden):\n",
    "        \"\"\"\n",
    "        args:\n",
    "        inputs(seq_len,batch,input_len): input sequence predict seq_len + 1\n",
    "        \"\"\"\n",
    "        seq_len = inputs.size()[0]\n",
    "        \n",
    "        # in case of 1 rnn layer output == hidden.\n",
    "        seqrnn_output, hidden = self._rnn_layer(inputs, hidden)\n",
    "        self.memory = seqrnn_output[-self._memory_size-1:-1]\n",
    "        hidden_t = seqrnn_output[-1].unsqueeze(0)\n",
    "        hidden_t_hat, alignment = self._atnn_layer(hidden_t, self.memory)\n",
    "        outputs = self._fc_out(hidden_t_hat)\n",
    "        \n",
    "        return outputs, alignment\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = Variable(torch.zeros(self._rnn_layers, batch_size, self._hidden_size))\n",
    "        hidden = hidden.cuda() if USE_CUDA else hidden\n",
    "        return hidden\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Helper functions **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(train, test):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(range(len(train)), train, range(len(test)), test)\n",
    "    \n",
    "def change_lr(optimizer, lr_new_val):\n",
    "    print(\"updating learning rate to: %f\"%lr_new_val)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr_new_val\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training procedure**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run model on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(input_seq, model, criterion, batch_size, train=False, optimizer=None):\n",
    "    \"\"\"\n",
    "    Train for a given sequence batch size.\n",
    "    Args:\n",
    "    input_seq(batch_size,seq_len,input_size): tensor containin sequences.\n",
    "    model: input model - batch is first dim.\n",
    "    criterion: distance measure i.e. l1, l2 etc.\n",
    "    optimizer: SGD, ADAM etc.\n",
    "    \"\"\" \n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    \n",
    "    input_seq = input_seq.transpose(0, 1)\n",
    "    preds, alignment = model(input_seq[:-1], hidden)\n",
    "    loss = criterion(preds, input_seq[-1])\n",
    "    \n",
    "    if train:\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return loss.data[0], preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a helper function to print time elapsed and estimated time remaining given the current time and progress %."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full train procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_procedure(train_data_np, valid_data_np, model, n_epoch, batch_size, learning_rate=0.01):\n",
    "    \n",
    "    plot_losses_avg = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    valid_losses = []\n",
    "    check_loss_every = 50\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    criterion = nn.MSELoss()\n",
    "    if USE_CUDA:\n",
    "        criterion = criterion.cuda()\n",
    "    \n",
    "    batchs_count = train_data_np.shape[0] / batch_size\n",
    "    \n",
    "    valid_batch_size = 20\n",
    "    valid_batchs_count = valid_data_np.shape[0] / valid_batch_size\n",
    "    \n",
    "    train_data = Variable(torch.from_numpy(train_data_np.astype('float32')), requires_grad=False)\n",
    "    valid_data = Variable(torch.from_numpy(valid_data_np.astype('float32')), requires_grad=False)\n",
    "    print(batchs_count)\n",
    "    for e in range(n_epoch):\n",
    "        \n",
    "        train_data = train_data[torch.randperm(train_data.shape[0])]\n",
    "\n",
    "        for batch_id in range(batchs_count):\n",
    "            train_batch = train_data[batch_id * batch_size : batch_id * batch_size + batch_size]\n",
    "            \n",
    "            loss, _ = run(train_batch, model, criterion, batch_size, train=True, optimizer=optimizer)\n",
    "            print_loss_total += loss\n",
    "            \n",
    "            if (batch_id + 1) % check_loss_every == 0:\n",
    "                plot_losses_avg.append(float(print_loss_total / check_loss_every))\n",
    "                print(\"[epoch %d : %d][batch %d : %d] train loss %f\"%\n",
    "                      (e, n_epoch, batch_id+1, batch_count,plot_losses_avg[-1]))\n",
    "        \n",
    "        valid_loss = 0\n",
    "        for batch_id in range(valid_batchs_count):\n",
    "            valid_batch = valid_data[batch_id * valid_batch_size : batch_id * valid_batch_size + valid_batch_size]\n",
    "            \n",
    "            loss, _ = run(valid_batch, model, criterion, valid_batch_size)\n",
    "            valid_loss += loss\n",
    "            \n",
    "        \n",
    "        valid_losses.append(float(valid_loss / valid_batchs_count))\n",
    "        print(\"[epoch %d : %d] valid loss %f\"%\n",
    "              (e, n_epoch, valid_losses[-1]))\n",
    "            \n",
    "        \n",
    "    show_plot(plot_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Main Entry Point **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and set hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (14850, 50, 24) validation shape: (781, 50, 24)\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape: {} validation shape: {}\".format(train_data.shape, valid_data.shape))\n",
    "\n",
    "input_size = train_data.shape[-1]\n",
    "hidden_size = input_size # disregarded when rnn_layers=1\n",
    "output_size = input_size\n",
    "batch_size = 60\n",
    "rnn_layers = 1\n",
    "memory_size = 30\n",
    "learning_rate = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "[epoch 0 : 100] valid loss 0.006827\n",
      "[epoch 1 : 100] valid loss 0.006661\n",
      "[epoch 2 : 100] valid loss 0.006691\n",
      "[epoch 3 : 100] valid loss 0.006688\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-a71f4e0dedb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_procedure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./saved_models/pred_nasa_seq\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-dac0f48fd6a7>\u001b[0m in \u001b[0;36mtrain_procedure\u001b[0;34m(train_data_np, valid_data_np, model, n_epoch, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mtrain_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_id\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_id\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-a5f225a3c4d4>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input_seq, model, criterion, batch_size, train, optimizer)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model = SeqRnnAttnAndPred(input_size=input_size, hidden_size=hidden_size, output_size=output_size,\n",
    "                          rnn_layers=rnn_layers, atnn_method='general',\n",
    "                          memory_size=memory_size)\n",
    "\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "\n",
    "train_procedure(train_data, valid_data, model, n_epoch=100, batch_size=120, learning_rate=learning_rate)\n",
    "\n",
    "torch.save(model.state_dict(), \"./saved_models/pred_nasa_seq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Run Evaluation **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_data, model, window_sz):\n",
    "    \n",
    "    loss_total = 0  # Reset every print_every\n",
    "    test_count = 0\n",
    "\n",
    "    criterion = nn.MSELoss().cuda()\n",
    "    \n",
    "    for seq in test_data:\n",
    "        seq_len = seq.shape[0]\n",
    "        for i in range(seq_len - window_sz):\n",
    "            test_seq = seq[i: i + window_sz]\n",
    "            test_seq = Variable(torch.from_numpy(test_seq.astype('float32')), requires_grad=False).unsqueeze(0)\n",
    "            if USE_CUDA:\n",
    "                test_seq = test_seq.cuda()\n",
    "            loss, _ = run(test_seq, model, criterion, 1, False)\n",
    "            loss_total += loss\n",
    "            test_count += 1\n",
    "    return loss_total / test_count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SeqRnnAttnAndPred(input_size=input_size, hidden_size=hidden_size, output_size=output_size,\n",
    "                          batch_size=1, rnn_layers=rnn_layers, atnn_method='general',\n",
    "                          memory_size=memory_size)\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "    \n",
    "model.load_state_dict(torch.load(\"./saved_models/pred_nasa_seq\"))\n",
    "\n",
    "\n",
    "evaluate(data_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
