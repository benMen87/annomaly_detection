{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIPRO TIME SERIERS - ANOMALY DETECTION AND SEQUENCE PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load NASA data \n",
    "\n",
    "[from dataset readme]\n",
    "The data are provided as a zip-compressed text file with 26 columns of numbers, separated by spaces. Each row is a snapshot of data taken during a single operational cycle, each column is a different variable. The columns correspond to:\n",
    "\n",
    "1)  unit number  \n",
    "2)  time, in cycles  \n",
    "3)  operational setting 1  \n",
    "4)  operational setting 2  \n",
    "5)  operational setting 3  \n",
    "6)  sensor measurement  1  \n",
    "7)  sensor measurement  2  \n",
    "...  \n",
    "26) sensor measurement  26  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit number</th>\n",
       "      <th>time in cycles</th>\n",
       "      <th>operational setting 1</th>\n",
       "      <th>operational setting 2</th>\n",
       "      <th>operational setting 3</th>\n",
       "      <th>sensor measurement 1</th>\n",
       "      <th>sensor measurement 2</th>\n",
       "      <th>sensor measurement 3</th>\n",
       "      <th>sensor measurement 4</th>\n",
       "      <th>sensor measurement 5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor measurement 12</th>\n",
       "      <th>sensor measurement 13</th>\n",
       "      <th>sensor measurement 14</th>\n",
       "      <th>sensor measurement 15</th>\n",
       "      <th>sensor measurement 16</th>\n",
       "      <th>sensor measurement 17</th>\n",
       "      <th>sensor measurement 18</th>\n",
       "      <th>sensor measurement 19</th>\n",
       "      <th>sensor measurement 20</th>\n",
       "      <th>sensor measurement 21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit number  time in cycles  operational setting 1  operational setting 2  \\\n",
       "0            1               1                -0.0007                -0.0004   \n",
       "1            1               2                 0.0019                -0.0003   \n",
       "2            1               3                -0.0043                 0.0003   \n",
       "3            1               4                 0.0007                 0.0000   \n",
       "4            1               5                -0.0019                -0.0002   \n",
       "\n",
       "   operational setting 3  sensor measurement 1  sensor measurement 2  \\\n",
       "0                  100.0                518.67                641.82   \n",
       "1                  100.0                518.67                642.15   \n",
       "2                  100.0                518.67                642.35   \n",
       "3                  100.0                518.67                642.35   \n",
       "4                  100.0                518.67                642.37   \n",
       "\n",
       "   sensor measurement 3  sensor measurement 4  sensor measurement 5  \\\n",
       "0               1589.70               1400.60                 14.62   \n",
       "1               1591.82               1403.14                 14.62   \n",
       "2               1587.99               1404.20                 14.62   \n",
       "3               1582.79               1401.87                 14.62   \n",
       "4               1582.85               1406.22                 14.62   \n",
       "\n",
       "           ...            sensor measurement 12  sensor measurement 13  \\\n",
       "0          ...                           521.66                2388.02   \n",
       "1          ...                           522.28                2388.07   \n",
       "2          ...                           522.42                2388.03   \n",
       "3          ...                           522.86                2388.08   \n",
       "4          ...                           522.19                2388.04   \n",
       "\n",
       "   sensor measurement 14  sensor measurement 15  sensor measurement 16  \\\n",
       "0                8138.62                 8.4195                   0.03   \n",
       "1                8131.49                 8.4318                   0.03   \n",
       "2                8133.23                 8.4178                   0.03   \n",
       "3                8133.83                 8.3682                   0.03   \n",
       "4                8133.80                 8.4294                   0.03   \n",
       "\n",
       "   sensor measurement 17  sensor measurement 18  sensor measurement 19  \\\n",
       "0                    392                   2388                  100.0   \n",
       "1                    392                   2388                  100.0   \n",
       "2                    390                   2388                  100.0   \n",
       "3                    392                   2388                  100.0   \n",
       "4                    393                   2388                  100.0   \n",
       "\n",
       "   sensor measurement 20  sensor measurement 21  \n",
       "0                  39.06                23.4190  \n",
       "1                  39.00                23.4236  \n",
       "2                  38.95                23.3442  \n",
       "3                  38.88                23.3739  \n",
       "4                  38.90                23.4044  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/home/hillel/projects/time_series/nasa_data/train_FD001.txt'\n",
    "header_names = ['unit number', 'time in cycles']  + ['operational setting %d'%i for i in range(1, 4)] + [ 'sensor measurement %d'%i for i in range(1, 24)]\n",
    "df = pd.read_csv(file_path, sep=' ', header=None, names=header_names)\n",
    "df = df.dropna(axis=1, how='all')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_test_data(df):\n",
    "    \n",
    "    amount_of_units_tot = df['unit number'].max()\n",
    "    amount_of_units_tst = 2\n",
    "    amunt_of_units_tr = amount_of_units_tot - amount_of_units_tst\n",
    "\n",
    "    test_units = np.random.choice(range(1, amount_of_units_tot+1), amount_of_units_tst)\n",
    "    train_units = [i for i in range(1, amount_of_units_tot + 1) if i not in test_units]\n",
    "\n",
    "    X_tr = []\n",
    "    X_tst = []\n",
    "\n",
    "    for idx in range(1, amount_of_units_tot + 1):\n",
    "        group_np = df[df['unit number'] == idx].iloc[:, 1:-1].as_matrix()\n",
    "        me = np.mean(group_np, axis=0)\n",
    "        std = np.std(group_np, axis=0)\n",
    "        group_np_norm = (group_np - me) / (std + 1e-12)\n",
    "        if idx in test_units:\n",
    "            X_tr.append(group_np_norm)\n",
    "        elif idx in train_units:\n",
    "            X_tst.append(group_np_norm)\n",
    "        else:\n",
    "            raise Exception(\"bad index %d ??\"%idx)\n",
    "    return X_tr, X_tst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Recurrent anttention based model\n",
    "\n",
    "The idea being learn the sequential dependencys and structure via gated rnn,\n",
    "and to learn spatial structure and similarity via attention mechanism. \n",
    "\n",
    "The Attention used in this case is inspired by https://arxiv.org/pdf/1508.04025.pdf\n",
    "Where the context vector is appended to final hiddent state and are passed to output layer.\n",
    "This differs to the standerd case where context is appended to input of the reccurent cell.\n",
    "\n",
    "The RNN sequence is inspired by https://arxiv.org/pdf/1308.0850.pdf\n",
    "Where LSTM based models are used for pedicting next time step.\n",
    "\n",
    "The code is mostly based on code found here:\n",
    "http://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrainBatch():\n",
    "    \n",
    "    def __init__(self, data, batch_sz, window_sz):\n",
    "        self._data = data\n",
    "        self._batch_sz = batch_sz\n",
    "        self._window_sz = window_sz\n",
    "        self._input_sz = data[0].shape[-1]\n",
    "        self._seq_len = [x.shape[0] for x in self._data]\n",
    "        self._curr_batch = None\n",
    "        \n",
    "    def next_batch(self):\n",
    "        \"\"\"\n",
    "        return:batch[(batch_size,seq_len,input_size)]\n",
    "        \"\"\"\n",
    "        batch = np.empty(shape=[self._batch_sz, self._window_sz, self._input_sz]) \n",
    "        amount_of_units = len(self._data)\n",
    "        choose_units = np.random.choice(amount_of_units, self._window_sz)\n",
    "    \n",
    "        for id, unit_id in zip(range(self._batch_sz), choose_units):\n",
    "            w_start_id = np.random.randint(0, self._seq_len[unit_id] - self._window_sz)\n",
    "            unit = self._data[unit_id][w_start_id:w_start_id+self._window_sz, :] # for unit get seq of window sz\n",
    "            batch[id,...] = unit\n",
    "        batch = Variable(torch.from_numpy(batch.astype('float32')), requires_grad=False)\n",
    "        if USE_CUDA:\n",
    "            batch = batch.cuda()\n",
    "        self._curr_data = batch\n",
    "        \n",
    "        return batch   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Recurrent model for capturing sequential information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SequencePredRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(SequencePredRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=False)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        output = inputs\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Attention model utilize reccurnt ouputs and their spatial similarity for predicting next time step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttendAndPredict(nn.Module):\n",
    "    \"\"\"Attention nn module that is responsible for computing the alignment scores.\"\"\"\n",
    "\n",
    "    def __init__(self, method, hidden_size, output_size):\n",
    "        super(AttendAndPredict, self).__init__()\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Define layers\n",
    "        if self.method == 'general':\n",
    "            self.attention = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attention = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "            self.other = nn.Parameter(torch.FloatTensor(1, self.hidden_size))\n",
    "            \n",
    "        self.fc_out = nn.Linear(self.hidden_size * 2, self.output_size)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, hidden, M):\n",
    "        \"\"\"Attend over N rnn sequence prediction outputs till time t-1 (t-2-N...t-1).\n",
    "        \n",
    "        After creating variables to store the attention energies, calculate their \n",
    "        values for each encoder output and return the normalized values.\n",
    "        \n",
    "        Args:\n",
    "            M(mem_size,batch,input size): memory of which to attend over.\n",
    "            hidden(1, batch, input size): hidden state.\n",
    "            \n",
    "        Returns:\n",
    "             Normalized (0..1) energy values, re-sized to 1 x 1 x seq_len\n",
    "        \"\"\"\n",
    "        \n",
    "        mem_size = M.size()[0]\n",
    "        batch_size = M.size()[1]\n",
    "        \n",
    "        # convert to batch first\n",
    "        M = M.permute(1,0,2)\n",
    "        hidden = hidden.permute(1,2,0)\n",
    "\n",
    "        energies = self._score(hidden, M)\n",
    "        a = F.softmax(energies)\n",
    "        c = a.permute(0,2,1).bmm(M)\n",
    "        next_timestep_prediction = self.fc_out(torch.cat((c.squeeze(1), hidden.squeeze(2)), 1))\n",
    "        \n",
    "        return next_timestep_prediction, a\n",
    "        \n",
    "    def _score(self, hidden, M):\n",
    "        \"\"\"\n",
    "        Calculate the relevance of a particular encoder output in respect to the decoder hidden.\n",
    "        Args:\n",
    "            hidden: decoder hidden output used for condition.\n",
    "            M(batch,seq_len,input_size): memory of which to attend over.\n",
    "            hidden(1, batch, input size): hidden state.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.method == 'dot':\n",
    "            # TODO: Not tested\n",
    "            energy = hidden.dot(M)\n",
    "        elif self.method == 'general':\n",
    "            energy = self.attention(M)\n",
    "            energy = torch.bmm(energy, hidden)#hidden.dot(energy)\n",
    "        elif self.method == 'concat':\n",
    "            # TODO: Not tested\n",
    "            energy = self.attention(torch.cat((hidden, M), 1))\n",
    "            energy = self.other.dor(energy)\n",
    "        return energy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SeqRnnAttnAndPred(nn.Module):\n",
    "    \"\"\"\n",
    "    SequenceAttnPred - Recurrent Atteniton based model for predicting next time step.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size,\n",
    "                 rnn_layers=1, atnn_method='general', memory_size=-1):\n",
    "        \"\"\"\n",
    "        args:\n",
    "        input_size: size of elemnt of sequnece.\n",
    "        hidden_size: size of hidden state of RNN (same as output if only 1 RNN).\n",
    "        output_size: size of output tensor.\n",
    "        rnn_layers: amount of stacked RNN's (see any basic seq2seq paper).\n",
    "        atnn_method: type of attention to use.\n",
    "        memory_size: amount of rnn output's to aggregate and attend over.\n",
    "        \"\"\"\n",
    "        super(SeqRnnAttnAndPred, self).__init__()\n",
    "        self._rnn_layer = SequencePredRNN(input_size, hidden_size, rnn_layers)\n",
    "        self._atnn_layer = AttendAndPredict(atnn_method, hidden_size, output_size)\n",
    "        self._memory_size = memory_size\n",
    "        self._batch_size = batch_size\n",
    "        \n",
    "    def forward(self, inputs, hidden):\n",
    "        \"\"\"\n",
    "        args:\n",
    "        inputs(seq_len,batch,input_len): input sequence predict seq_len + 1\n",
    "        \"\"\"\n",
    "        seq_len = inputs.size()[0]\n",
    "        \n",
    "        # in case of 1 rnn layer output == hidden.\n",
    "        seqrnn_output, hidden = self._rnn_layer(inputs, hidden)\n",
    "        self.memory = seqrnn_output[-self._memory_size-1:-1]\n",
    "        hidden_t = seqrnn_output[-1].unsqueeze(0)\n",
    "        outputs, alignment = self._atnn_layer(hidden_t, self.memory)\n",
    "        return outputs, alignment\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(1, self._batch_size, self._rnn_layer.hidden_size))\n",
    "        hidden = hidden.cuda() if USE_CUDA else hidden\n",
    "        return hidden\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Helper functions **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training procedure**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run model on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(input_seq, model, criterion, train=False, optimizer=None):\n",
    "    \"\"\"\n",
    "    Train for a given sequence batch size.\n",
    "    Args:\n",
    "    input_seq(batch_size,seq_len,input_size): tensor containin sequences.\n",
    "    model: input model - batch is first dim.\n",
    "    criterion: distance measure i.e. l1, l2 etc.\n",
    "    optimizer: GD, ADAM etc.\n",
    "    \"\"\"  \n",
    "    input_seq = input_seq.transpose(0, 1)\n",
    "    hidden = model.init_hidden()\n",
    "    preds, alignment = model(input_seq[:-1], hidden)\n",
    "    loss = criterion(preds, input_seq[-1])\n",
    "    \n",
    "    if train:\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return loss.data[0], preds\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a helper function to print time elapsed and estimated time remaining given the current time and progress %."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full train procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainIters(train_batch, model, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    \n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss().cuda()\n",
    "  \n",
    "\n",
    "    for iter in range(1, n_iters):\n",
    "        \n",
    "        curr_batch = train_batch.next_batch()\n",
    "        \n",
    "        loss, _ = run(curr_batch, model, criterion, True, optimizer)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, float(iter) / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "    show_plot(plot_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(test_data, model, print_every=1000, plot_every=100):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Main Entry Point **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 30s (- 9m 48s) (5000 0%) 0.1641\n",
      "1m 1s (- 9m 12s) (10000 0%) 0.1456\n",
      "1m 31s (- 8m 40s) (15000 0%) 0.1424\n",
      "2m 2s (- 8m 11s) (20000 0%) 0.1399\n",
      "2m 33s (- 7m 39s) (25000 0%) 0.1377\n",
      "3m 3s (- 7m 8s) (30000 0%) 0.1375\n",
      "3m 34s (- 6m 38s) (35000 0%) 0.1352\n",
      "4m 4s (- 6m 7s) (40000 0%) 0.1345\n",
      "4m 35s (- 5m 36s) (45000 0%) 0.1337\n",
      "5m 5s (- 5m 5s) (50000 0%) 0.1331\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = get_train_test_data(df)\n",
    "\n",
    "input_size = data_train[0].shape[-1]\n",
    "output_size = input_size\n",
    "batch_size = 64\n",
    "hidden_size = input_size # disregarded when rnn_layers=1\n",
    "rnn_layers = 1\n",
    "memory_size = 15\n",
    "window_size = 30 # what is the window we train over\n",
    "\n",
    "model = SeqRnnAttnAndPred(input_size=input_size, hidden_size=hidden_size, output_size=output_size,\n",
    "                          batch_size=batch_size, rnn_layers=rnn_layers, atnn_method='general',\n",
    "                          memory_size=memory_size)\n",
    "\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "    \n",
    "train_batch = TrainBatch(data_train, batch_size, window_size)\n",
    "trainIters(train_batch, model, 100000, print_every=5000)\n",
    "torch.save(model.state_dict(), \"./saved_models/pred_nasa_seq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
